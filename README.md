# Learning Path Optimization Using Regression & Neural Networks

This project focuses on building a recommendation system to optimize learning paths for students preparing for technical interviews. By leveraging regression models and neural networks, it highlights the most frequently asked topics in Data Structures & Algorithms (DSA) and core Computer Science (CS) subjects. This system provides targeted study recommendations, helping students prioritize their learning effectively.

## Features

- **Data Preprocessing**: Min-Max Normalization and One-Hot Encoding for data preparation.
- **Modeling**: Regression and neural network models to predict optimal learning paths.
- **Recommendations**: Personalized study suggestions based on data analysis.
  
## Technologies Used

- **Python** for core programming
- **scikit-learn** for preprocessing and regression
- **TensorFlow/Keras** for neural network models
- **NumPy & Pandas** for data manipulation
- **Matplotlib/Seaborn** for data visualization

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/KevinMenpara/LPO-Using-Neural-Network.git
    ```

2. Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the model:
    ```bash
    python main.py
    ```

## Contributors

- Kevin Menpara (202101079)
- Krisha Brahmbhatt (202201164)
- Dipesh Verma (202201126)
- Visvas Solanki (202101138)
- Pooja Yogi (202321012)

## References

1. [Min Max Normalization](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html)
2. [One Hot Encoding](https://ersj.eu/journal/3388/download/Use+of+Autoencoder+and+One-Hot+Encoding+for+Customer+Segmentation.pdf)
3. [Neural Network Architecture](https://core.ac.uk/download/pdf/234645196.pdf)
4. [Mean Squared Error (MSE)](https://www.sciencedirect.com/topics/engineering/mean-square-error)
5. Sekhar, Ch & Meghana, P. (2020). A Study on Backpropagation in Artificial Neural Networks. Asia-Pacific Journal of Neural Networks and Its Applications, 4, 21-28. 10.21742/AJNNIA.2020.4.1.03.
6. [Adam Optimizer](https://arxiv.org/pdf/1412.6980)
